<!DOCTYPE html>
<!-- 
Basic RASH template - Version 1.1, December 31, 2016
by Silvio Peroni

This work is licensed under a Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/).
You are free to:
* Share - copy and redistribute the material in any medium or format
* Adapt - remix, transform, and build upon the material
for any purpose, even commercially.

The licensor cannot revoke these freedoms as long as you follow the license terms.

Under the following terms:
* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.
-->
<html 
    xmlns="http://www.w3.org/1999/xhtml" 
    prefix="
        schema: http://schema.org/
        prism: http://prismstandard.org/namespaces/basic/2.0/">
    <head>
        <!-- Visualisation requirements (mandatory for optimal reading) -->
        <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1"/>
        
        <link rel="stylesheet" href="css/bootstrap.min.css"/>
        <link rel="stylesheet" href="css/rash.css"/>
        
        <script src="js/jquery.min.js"> </script>
        <script src="js/bootstrap.min.js"> </script>
        <script src="js/rash.js"> </script>
        
        <!-- MathJax for multi-browser support of LaTeX formulas and MathML -->
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_HTMLorMML"> </script>
        <!-- /END Visualisation requirements (mandatory for optimal reading) -->
        
        <!-- Metadata -->
        <title property="dcterms:title">Graphless -- Using Statistical Analysis and Heuristics for Visualazing Large Datasets</title>
        
        <!-- Author's data (one or more) -->
        <meta about="http://w3id.org/people/idafensp" name="dc.creator" content="Idafen Santana-Perez"/>
        <meta about="http://w3id.org/people/idafensp" property="schema:email" content="isantana@fi.upm.es"/>
        <link about="http://w3id.org/people/idafensp" property="schema:affiliation" href="http://www.oeg-upm.net/"/>
        
        
        <!-- Affiliations -->
        <meta about="http://www.oeg-upm.net/" property="schema:name" content="Ontology Engineering Group - Universidad Polit&eacute;cnica de Madrid, Spain"/>
        
        <!-- Paper keywords (one or more) -->
        <meta property="prism:keyword" content="Knowledge Graphs"/>
        <meta property="prism:keyword" content="Data Visualization"/>
        <meta property="prism:keyword" content="Entity Summarisation"/>
        <meta property="prism:keyword" content="Statistical Analysis"/>
        <meta property="prism:keyword" content="Graph Exploration"/>
        
    </head>
    <body>
        <!-- Abstract -->
        <section role="doc-abstract">
            <h1>Abstract</h1>
            <p>Data visualisation over semantic datasets and Knowledge Graphs becomes a challenging task as the data volume increases. The amount of nodes and edges linking them produce overwhelming diagrams in which understanding the information displayed is cumbersome. In this work we introduce Graphless, a visualisation interface that exploits the statistical information of the usage of instances and relations to produce graphical summaries of entities. The system supports several heuristics, providing different visualisations, according to configurable parameters. </p>
        </section>
        
        <!-- Sections -->
        <section id="intro">
            <h1>Introduction</h1>
            <p>
                Graphless is an online tool<a href="#glonline"></a> that provides a user interface for graphically exploring RDF-based datasets. The main goal of this tool is to provide a way for summarizing entity graphs,supporting a better understanding of how individuals and their relations are stated. In a way, our aim is to reduce big portions of data to a more easy to digest representation, trying to preserve the most relevant elements while doing so.
            </p>
            
            <p> 
                For doing so, we have to consider the data features that semantic datasets have. In the most basic and common scenario, semantic data is represented as a graph of individuals and properties linking them. Even when an schema, defined as an ontology, could be expected, having it is not always the case. Many available SPARQL endpoints hosting datasets do not contain the ontology (or ontologies) used to generate them. In this work we aim to provide a generic approach for producing visualization summaries. We rely only on the statistical features that are common to RDF data graphs. We consider the following two main features:
            </p>
            <ul>
                <li><p><strong>Connectivity degree:</strong>
                        the number of ingoing and outgoing links from/to a given node is an indicator of the relevance of the node in the dataset. Central nodes (e.g <em>Countries</em> as birthplaces, <em>Years</em> for dates) tend to have many incoming links, as they are referenced by many other instances. Also, nodes of prominent entities usually assert many outgoing properties, either to other entities or to literal values (e.g. <em>Authors</em> to the books they wrote, <em>Places</em> to their names in different languages).
                    </p></li>
                <li><p><strong>Property usage:</strong>
                        the distribution of properties along the instances on a dataset is, as expected, not strictly homogeneous. Properties such as <em>name</em> or <em>birthplace</em> are more likely to  be instantiated on instances of type <em>Person</em> than others such as <em>capital of</em> or <em>foundation year</em>. Thus, classes allow us to estimate which are the most used properties for their instances.
                    </p></li>
            </ul>
            
            We use these two factors to analyze the structure of the data graph, and based on the results obtained, the system decides which element to depict on the final diagram. From the two explanations above, we derive the following tentative assumptions when summarizing data visualizations, which are the base of our system.

            <ol>
                <li>
                    Users are more interested in exploring nodes that have more connections, as they are more relevant.
                </li>
                <li>
                    Users are more interested in visualizing the most frequently used properties for the nodes depicted, as they provide more insights.
                </li>
            </ol>
            
            These two assumptions may seem quite straightforward, but as we discuss in this work, they allow to build informative data visualizations, by using then for analyzing the data graph. Whereas other features could be also included (e.g. ontology taxonomy, discriminative properties), these two ones are appropriate as they often apply to any given dataset. 
            
            <figure id="figure_1">
                <p>
                    <img width="80%" src="images/glguiscreen.png" alt="Graphless GUI example" />
                </p>
                <figcaption>Graphless online GUI example.</figcaption>
            </figure>

            The final goal of the system presented in this work is to generate summarized graph diagrams, to provide a better visual exploration experience. An illustrative example of the final product is shown in <a href="#figure_1"></a>, which depicts the Graphless GUI with a summary of an entity from a semantic dataset. The remainder of this paper will introduce how to calculate these summaries and display them, explaining as well how the system is being currently used for the Jamendo dataset<a href="#dbtune"></a>, which contains a large collection of data about records, music artists, songs, lyrics and genres.
        </section>
        
        <section id="analysis">
            <h1>Analyzing the graph</h1>
            <p>
                In order for the interface to be able to filter and display the data properly, the target graph has to be analyzed according to the metrics described previously. This process starts by retrieving the list resources and their corresponding types from the dataset. Using this information the system counts how many times each property is instantiated, keeping track of the type of the subject of the triple as well as of the object (only for object properties). 
            </p>
            <p>
                In this process, the system records the statistical usage of properties, both as ingoing and outgoing links of instances of each type. We define a property as outgoing for a given type when an instance of such type is used as the subject of a triple. Similarly, outgoing properties of a type are those that appear on triples with an object belonging to that type.

            </p>
            <p>
                With this information, the system is able to generate a profile for each type in the dataset, assigning weights to each type-property combination. In order to have a relative measure, raw counts are normalized for each type, generating a weight value from 0 to 1. Values closer to 1 would imply highly used properties, and thus highly relevant, following the discussion introduced previous section. Those properties with weights close to 0 imply that these properties are low in relevance as they are rarely used. 
            </p>

            <p>
                The result of this process is exemplified in <a href="#table_analysis_props"></a> which displays the statistic analysis of the Jamendo dataset, which we will describe in <a href="#results"></a>. The table depicts the property counts for the class <em>mo:MusicArtist</em><a href="#prefixes"></a> in the dataset, including the total and normalized counts for both ingoing and outgoing properties.

            </p>

            <figure id="table_analysis_props">
                <table>
                    <tr>
                        <th rowspan="1" colspan="1">Property</th>
                        <th rowspan="1" colspan="1">Prop.Type</th>
                        <th rowspan="1" colspan="1">Count</th>
                        <th rowspan="1" colspan="1">Normalized weight</th>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>foaf:made</em></p></td>
                        <td rowspan="1" colspan="1"><p>Outgoing</p></td>
                        <td rowspan="1" colspan="1"><p>5786</p></td>
                        <td rowspan="1" colspan="1"><p>1.0</p></td>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>foaf:based_near</em></p></td>
                        <td rowspan="1" colspan="1"><p>Outgoing</p></td>
                        <td rowspan="1" colspan="1"><p>3244</p></td>
                        <td rowspan="1" colspan="1"><p>0.5606</p></td>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>foaf:name</em></p></td>
                        <td rowspan="1" colspan="1"><p>Outgoing</p></td>
                        <td rowspan="1" colspan="1"><p>3505</p></td>
                        <td rowspan="1" colspan="1"><p>0.6057</p></td>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>foaf:homepage</em></p></td>
                        <td rowspan="1" colspan="1"><p>Outgoing</p></td>
                        <td rowspan="1" colspan="1"><p>3006</p></td>
                        <td rowspan="1" colspan="1"><p>0.5195</p></td>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>foaf:img</em></p></td>
                        <td rowspan="1" colspan="1"><p>Outgoing</p></td>
                        <td rowspan="1" colspan="1"><p>2982</p></td>
                        <td rowspan="1" colspan="1"><p>0.5154</p></td>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>mo:biography</em></p></td>
                        <td rowspan="1" colspan="1"><p>Outgoing</p></td>
                        <td rowspan="1" colspan="1"><p>485</p></td>
                        <td rowspan="1" colspan="1"><p>0.0838</p></td>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>owl:sameAs</em></p></td>
                        <td rowspan="1" colspan="1"><p>Outgoing</p></td>
                        <td rowspan="1" colspan="1"><p>119</p></td>
                        <td rowspan="1" colspan="1"><p>0.0206</p></td>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>foaf:maker</em></p></td>
                        <td rowspan="1" colspan="1"><p>Ingoing</p></td>
                        <td rowspan="1" colspan="1"><p>5786</p></td>
                        <td rowspan="1" colspan="1"><p>1.0</p></td>
                    </tr>
                </table>
                <figcaption>Usage of properties for class <em>mo:MusicArtist</em>.</figcaption>
            </figure>

            <p>
                Besides the property usage for each type, the system also analyzes how many properties link to each resource in the dataset, obtaining the ingoing and outgoing degree for each node (i.e. individual) in the graph. These measurements indicate the connectivity degree of the node, and serve as indicators of the relevance of the node in the graph. Intuitively, the more connected a node is, the more relevant it is.  

            </p>
            <p>
                <a href="#table_analysis_nodes"></a> shows the information generated during this process for a set of resources belonging to different classes. As explained for the previous process, the system normalizes the raw counts, so as to have a consistent measurement of the importance of the node in the graph. This is achieved by dividing each ingoing and outgoing count by the corresponding maximum value found on the graph.
            </p>

            <figure id="table_analysis_nodes">
                <table>
                    <tr>
                        <th rowspan="1" colspan="1">Resource</th>
                        <th rowspan="1" colspan="1">Type</th>
                        <th rowspan="1" colspan="1">Ingoing Deg.</th>
                        <th rowspan="1" colspan="1">Outgoing Deg.</th>
                        <th rowspan="1" colspan="1">Norm. In. Deg.</th>
                        <th rowspan="1" colspan="1">Norm. In. Deg.</th>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>http://dbtune.org/jamendo/record/3280</em></p></td>
                        <td rowspan="1" colspan="1"><p><em>mo:Record</em></p></td>
                        <td rowspan="1" colspan="1"><p>1</p></td>
                        <td rowspan="1" colspan="1"><p>109</p></td>
                        <td rowspan="1" colspan="1"><p>0.00009</p></td>
                        <td rowspan="1" colspan="1"><p>1.0</p></td>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>http://dbtune.org/jamendo/artist/1442</em></p></td>
                        <td rowspan="1" colspan="1"><p><em>mo:MusicArtist</em></p></td>
                        <td rowspan="1" colspan="1"><p>25</p></td>
                        <td rowspan="1" colspan="1"><p>54</p></td>
                        <td rowspan="1" colspan="1"><p>0.0022</p></td>
                        <td rowspan="1" colspan="1"><p>0.2660</p></td>
                    </tr>
                    <tr>
                        <td rowspan="1" colspan="1"><p><em>http://dbtune.org/jamendo/lyrics/23855</em></p></td>
                        <td rowspan="1" colspan="1"><p><em>mo:Lyrics</em></p></td>
                        <td rowspan="1" colspan="1"><p>1</p></td>
                        <td rowspan="1" colspan="1"><p>1</p></td>
                        <td rowspan="1" colspan="1"><p>0.00009</p></td>
                        <td rowspan="1" colspan="1"><p>0.0091</p></td>
                    </tr>
                </table>
                <figcaption>Ingoing and outgoing degree for different resources</figcaption>
            </figure>

            <p>
                Once these two analysis (i.e. properties usage and connectivity degree) have been conducted, their results are combined, assigning to each node on the graph the corresponding information. That is, each node in the graph will be annotated with the connectivity degrees and the usage weights for each property instantiated for it, both for ingoing and outgoing properties. As discussed in <a href="#implementation"></a> the property weights annotations are done using the relationship features of Neo4j<a href=#neo4j></a>.
            </p>
            <figure id="fig_1442">
                <p>
                    <img width="80%" width="80%" src="images/1442.png" alt="Properties of <em>http://dbtune.org/jamendo/artist/1442</em>" />
                </p>
                <figcaption>Properties of <em>http://dbtune.org/jamendo/artist/1442</em></figcaption>
            </figure>            

            <p>
                As depicted in <a href="#fig_1442"></a>, each property of the resource <em>http://dbtune.org/jamendo/artist/1442</em> is annotated with their corresponding weights, along with the ingoing and outgoing degrees of the resource. These parameters can be used to filter and reduce the elements to be displayed on the final diagram, as we introduce in the following section.
            </p>
        
        </section>
        
        <section id="heuristics">
            <h1>Heuristics</h1>

            The results obtained by the statistical analysis are the base for a set of algorithms that explore the graph to generate a summarized visualization. The current version of the system includes two different algorithms that can be used to explore a dataset. The following sections introduce them. In both cases, the algorithm requires a root node to be selected, as the starting point to traverse the graph. Depending on the algorithm, different parameters can be defined. As well, when selecting the properties to be displayed, the system considers both ingoing and outgoing ones, using the different weights associated to them.


            <section id="Top K heuristic">
                <h2>Top-K heuristic</h2>

                This algorithm implements an straightforward heuristic for traversing the graph, selecting only the top relevant properties on each step. Starting on the root node, the algorithm selects the K top properties of the node, which link to new nodes. The process recursively executes the same steps obtaining new nodes. In order to restrict the amount of nodes being explored, the algorithim limits the number of steps in the process to a maximum depth, defining how deep the graph can be explored from the starting node. <a href=#fig_topk></a> shows an example of the Top K algorithm, starting from the node <em>http://dbtune.org/jamendo/artist/7373</em>, selecting the two top properties, with a max depth of five, as shown on the right-hand side of the picture. That is, for each node the system picks only the two most relevant properties, and keeps on traversing the graph until it reaches nodes separated by five steps from the root resource. In this case, to calculate which properties are the most relevant, the system multiplies the weight of the property by the weight of the node that it links to, providing a combined measure of the importance of the property and the target node in the graph.

                <figure id="fig_topk">
                    <p>
                        <img width="80%" src="images/topk_example.png" alt="Example of the Top K algorithm" />
                    </p>
                    <figcaption>Example of the Top K algorithm</em></figcaption>
                </figure>    
            </section>

            <section id="threshold">
                <h2>Threshold heuristic</h2>

                This algorithm selects all the properties that have a weight higher than a given threshold value, and retrieves all their associated nodes. In the first step, the given threshold parameter is used to filter. After that, for all the retrieved nodes the process is repeated, increasing the threshold value as specified by the decay parameter. This way, the threshold is higher on each step, until it reaches the maximum value for a property weight (i.e. 1.0), which will stop the process. <a href="#fig_thresh"></a> shows the diagram resulting of using this algorithm for the same resource from the previous example (i.e. <em>http://dbtune.org/jamendo/artist/7373</em>) with a base threshold of 0.8, and a decay of 0.1. Thus, for the first iteration only properties with a value higher than 0.8 will be selected, then only those higher than 0.9, and once the value 1.0 is reached, the system stops, as this is the maximum weight for any property.

                <figure id="fig_thresh">
                    <p>
                        <img width="80%" src="images/thresh_example.png" alt="Example of the Threshold algorithm" />
                    </p>
                    <figcaption>Example of the Threshold algorithm</em></figcaption>
                </figure>    
            </section>

            When comparing <a href="#fig_topk"></a> and <a href="#fig_thresh"></a>, we can observe how the system provides different visualizations based on the same dataset, by applying different heuristics. In the coming sections we will discuss about how this system is implemented and how the usage of a graph-oriented database allows to store the required annotations and perform queries using them efficiently.

        </section>
        
        
        <section id="implementation">
            <h1>Implementation</h1>
            <section id="gui">
                <h2>Data management</h2>
        
                <p>
                    The information extracted from the process described in <a href="#analysis"></a> has to be stored in a way that can be accessed efficiently. This requires a data system able to support the annotation of properties and nodes. Both things could be done using just RDF over the original dataset, using custom properties for annotating nodes and reification statements for the properties. However we decided to use a more graph-oriented solution, providing better performance and ease of use when querying the data. The use of extra properties, and specially the use of reification, would increase the complexity of SPARQL queries, difficulting the process of exploring the graph.
                </p>

                <p>
                    For these reasons, we selected Neo4j<a href=#neo4j></a> as our data backend solution, for storing the dataset and the related annotations. This graph database offers the required features for storing the nodes and the properties (known as relationships according to Neo4j's naming conventions), with annotations for both of them. These annotations can be used directly in Cypher<a href=#cypher></a> queries, the query language used in Neo4j. <a href="#listing_1"></a>, shows the two types queries used for the Top-K and Threshold algorithms respectively. As we can see, we can exploit the annotations over the properties (&quot;r&quot; in both examples) to either sort by weight and select the top two properties (top-k heuristic) or to filter based on the weight being higher than a given value (threshold heuristic).

                    <figure id="listing_1">
                        <pre>
                            <code>
MATCH (n:JARLABS)-[r:JARLABS]->(x:JARLABS) WHERE n.nodeid = '...' RETURN ... ORDER BY r.weight DESC LIMIT 2

MATCH (n:JARLABS)-[r:JARLABS]->(x:JARLABS) WHERE n.nodeid = '...' AND r.weight > 0.8 RETURN ...
                            </code>
                        </pre>
                        <figcaption>Cypher queries (shortened using &quot;&hellip;&quot;)</figcaption>
                    </figure>


                </p>

            </section>
            <section id="gui">
                <h2>User interface</h2>

                <p>
        
                	The frontend of the system is developed as a web interface, which aims to provide a clean and clear visualization experience to the final user. The graphs visualization is supported by <em>vis.js</em><a href=#visjs></a>, a popular Javascript library for drawing statical reports, graphs and relation diagrams on the web. The interface itself is composed by two parts, the main area, in which graphs are displayed, and the right menu, which is hidden by default in order to maximize the visualisation space.

           		</p>
           		<p>

            		As depicted in the GUI figures in this paper, the graphs are displayed in the main area, following a shade color scheme. The root node, the one the user queried, is displayed with the strongest red hue. As the distance from this root node increases, the color code of the node gets lighter and lighter. Circles and nodes are used to differentiate between object nodes and literal ones respectively. In both cases, the local name or the literal value are used as the node label. Properties are also labeled with their name and weight.

            	</p>
            	<p>
            		All nodes are clickable objects. On double click, the right menu is opened and the information about the selected node is displayed, as seen in <a href="#fig_menu"></a>. 
            	</p>

                <figure id="fig_menu">
                    <p>
                        <img width="80%" src="images/menu.png" alt="Right menu information panel" />
                    </p>
                    <figcaption>Right menu information panel</em></figcaption>
                </figure>   


            </section>
            <br>
            <p>
                The code, implemented in Java, is divided in two different projects, for the analysis process and interface, which are available online<a href="#ghcode_lds"></a><a href="#ghcode_ldv"></a>.
            </p>
        </section>

       

        
        <section id="results">
            <h1>Jamendo Results</h1>

            <p>
            	As we have mentioned before, the current version of Graphless includes the Jamendo dataset, which contains information about records,  musical artists, torrents, lyrics, signals, tags, documents and tracks. It combines five different ontologies and contains 412,564 object nodes, 251,698 literals, and a total of 1,267,012 instantiated relations. 
            </p>

            <p>
            	The data ingestion process, undertaken during the analysis process, starts by querying the public Jamendo endpoint<a href="#jamendosparql"></a>, from which the system retrieves all the subjects, objects, and their related properties and types. This is done by means of SPARQL queries, which are executed with a time delay between them to avoid overloading the system.
            </p>

            <p>
            	Jamendo individuals and properties can be visualized on the currently available version of Graphless, using the two exploratory algorithms described above. The final dataset is also available as a Neo4j database<a href="#jamendodata"></a>
            </p>
        
        </section>
        
        <section id="related">
            <h1>Related work</h1>

            <p>
            	This work is inspired by the SDType <a href="#sdtype"></a> system, which uses statistical analysis of datasets to infer missing entity types. In our case, we flip this approach, using the types of the entities as indicator of the importance of the properties asserted for their individuals. This way, we can select those that are commonly used for each type.
            </p>

            <p>
            	As discussed before, the final goal of our system is to provide visualization summaries of entities. In this direction, several approaches have been proposed for entity summarisation. LinkSUM <a href="#linksum"></a> and <a href="#summarum"></a> pursue a goal similar to the one exposed in this work, aiming to reduce the number of properties displayed for an entity. In this case, authors propose to use the well-known PageRank algorithm for calculating the relevance of properties. This score is then used for selecting the top properties of an entity, without traversing the graph, as we do in this work. A similar approach, obtaining lower results than LinkSUM is introduced in FACES <a href="#faces"></a>
            </p>
            
            <p>
            	Other systems have been proposed for graph summarisation in the context of Linked Data <a href="#chawuthai"></a>. This work combines graph simplification, ranking of triples, and property selection, providing a semi-automatic way of generating summaries by the user. A more recent approach <a href="#vowlzoom"></a> has been proposed for summarising semantic entities in a graphical manner. Following the VOWL <a href="#vowl"></a> notation for ontology visualization, authors introduce the usage of zooming techniques for reducing the complexity of the graph being visualized. The system summarises the graph depending on the granularity selected, rather than on the relevance of the elements that compose the graph. The challenge this system faces and solves resides in preserving the meaning of the overall graph while merging different entities into a single one.
            </p>
        
        </section>
        
        <section id="discussion">
            <h1>Discussion and Future Work</h1>

            <p>
            	In this paper we introduce Graphless, a data visualization tool for semantic datasets, which combines statistical analysis and graph traverse heuristics to produce graph summaries. Combining these two approaches the system is able to provide smaller diagrams, which are easier to read and interpret. 
            </p>
            <p>
            	This work represents a first version of the tool, in which only the Jamendo dataset has been included. We plan to extend the collection of datasets, including more representative ones, such as DBpedia. Our intuition is that a tool such as this would be of help specially in heterogeneous datasets, containing information from different sources and with a wide range of varied types and properties.
            </p>
            <p>
            	From the technical point of view, we plan to include new features, currently under development, such as the generation of RDF snippets from the visualizations. We also plan to support new algorithms implementing novel heuristics. Our final goal is to provide a programmable interface in which developers can integrate their algorithms based on the available data properties.
            </p>
            <p>
            	Finally, we are currently conducting a usability evaluation with several users, which will provide feedback for improving the tool.
            </p>
        
        </section>
        
        <!-- Acknowledgements -->
        <section role="doc-acknowledgements">
            <h1>Acknowledgments</h1>
            <p>This work was partially funded by the esTextAnalytics (RTC-2016-4952-7) project, from the Spanish State Investigation Agency of the MINECO and FEDER Funds.</p>
        </section>
        
        <!-- References -->
        <section id="bibreflist" role="doc-bibliography">
            <h1>References</h1>
            <ol>
                <li id="dbtune" role="doc-biblioentry"><p>Y Raimond, MB Sandler, Q Mary: A Web of Musical Information, ISMIR, 2008</p></li>
                
                <li id="sdtype" role="doc-biblioentry"><p>Heiko Paulheim and Christian Bizer: Type Inference on Noisy RDF Data. In: Lecture notes in computer scienceThe Semantic Web - ISWC 2013 : 12th International Semantic Web Conference, Sydney, NSW, Australia, October 21-25, 2013, Proceedings, Part I; 510-525. Springer, Berlin [u.a.], 2013.</p></li>Web of Musical Information, ISMIR, 2008</p></li>
                
                <li id="linksum" role="doc-biblioentry"><p>Thalhammer, Andreas, Nelia Lasierra and Achim Rettinger. &quot;LinkSUM: Using Link Analysis to Summarize Entity Data.&quot; ICWE (2016).</p></li>
                
                <li id="summarum" role="doc-biblioentry"><p>Thalhammer, Andreas and Achim Rettinger. &quot;Browsing DBpedia Entities with Summaries.&quot; ESWC (2014).</p></li>

                <li id="faces" role="doc-biblioentry"><p>Kalpa Gunaratna, Krishnaprasad Thirunarayan, and Amit Sheth. 2015. FACES: diversity-aware entity summarization using incremental hierarchical conceptual clustering. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI'15). AAAI Press 116-122.</p></li>

                <li id="vowlzoom" role="doc-biblioentry"><p>Vitalis Wiens, Steffen Lohmann, and Sören Auer. 2017. Semantic Zooming for Ontology Graph Visualizations. In Proceedings of the Knowledge Capture Conference (K-CAP 2017). ACM, New York, NY, USA, Article 4, 8 pages. DOI: https://doi.org/10.1145/3148011.3148015</p></li>

                <li id="vowl" role="doc-biblioentry"><p>Lohmann, S.; Link, V.; Marbach, E.; Negru, S.: WebVOWL: Web-Based Visualization of Ontologies. Proceedings of EKAW 2014 Satellite Events, LNAI 8982, pp. 154-158, Springer, 2015</p></li>

                <li id="chawuthai" role="doc-biblioentry"><p>Chawuthai R., Takeda H. (2016) RDF Graph Visualization by Interpreting Linked Data as Knowledge. In: Qi G., Kozaki K., Pan J., Yu S. (eds) Semantic Technology. JIST 2015. Lecture Notes in Computer Science, vol 9544. Springer, Cham</p></li>




            </ol>
        </section>
        
        <!-- Footnotes -->
        <section id="fnlist" role="doc-endnotes">
            <section id="glonline" role="doc-endnote">
                <p><a href="http://graphless.linkeddata.es/">http://graphless.linkeddata.es/</a></p>
            </section>
            <section id="neo4j" role="doc-endnote">
                <p><a href="https://neo4j.com/">https://neo4j.com/</a></p>
            </section>
            <section id="cypher" role="doc-endnote">
                <p><a href="https://neo4j.com/developer/cypher-query-language/">https://neo4j.com/developer/cypher-query-language/</a></p>
            </section>
            <section id="visjs" role="doc-endnote">
                <p><a href="http://visjs.org/">http://visjs.org/</a></p>
            </section>
            <section id="jamendourl" role="doc-endnote">
                <p><a href="http://dbtune.org/jamendo/">http://dbtune.org/jamendo/</a></p>
            </section>
            <section id="ghcode_lds" role="doc-endnote">
                <p><a href="https://github.com/idafensp/graphless-lds">https://github.com/idafensp/graphless-lds</a></p>
            </section>
            <section id="ghcode_ldv" role="doc-endnote">
                <p><a href="https://github.com/idafensp/graphless-ldv">https://github.com/idafensp/graphless-ldv</a></p>
            </section>
            <section id="jamendosparql" role="doc-endnote">
                <p><a href="http://dbtune.org/jamendo/sparql">http://dbtune.org/jamendo/sparql</a></p>
            </section>
            <section id="jamendodata" role="doc-endnote">
                <p><a href="https://doi.org/10.5281/zenodo.1284979">https://doi.org/10.5281/zenodo.1284979</a></p>
            </section>
            <section id="prefixes" role="doc-endnote">
                <p>The following prefixes are used throughout the text: <em>mo</em> (http://purl.org/ontology/mo/), <em>foaf</em> (http://xmlns.com/foaf/0.1/), <em>tag</em> (http://www.holygoat.co.uk/owl/redwood/0.1/tags/), <em>owl</em> (http://www.w3.org/2002/07/owl#)</p>
            </section>
        </section>
    </body>
</html>
